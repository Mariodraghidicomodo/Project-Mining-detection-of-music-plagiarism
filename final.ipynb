{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mido\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_melody(file):\n",
    "    M = []\n",
    "    for i, track in enumerate(file.tracks):\n",
    "        for msg in track:\n",
    "            if msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0): \n",
    "                M.append(msg.note)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_delta(M):\n",
    "    Vm = []\n",
    "    for i in range(len(M)-1):\n",
    "            delta = M[i+1] - M[i]\n",
    "            Vm.append(delta)\n",
    "    return Vm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert ticks to time in seconds, TEST2\n",
    "def tick_to_time_test2(ticks, tempo, ticks_per_quarter_note):\n",
    "    \n",
    "    duration_per_tick = tempo / ticks_per_quarter_note\n",
    "    \n",
    "    note_duration = duration_per_tick * ticks\n",
    "    \n",
    "    note_duration_seconds = note_duration / 1000000\n",
    "    \n",
    "    \n",
    "    return note_duration_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_duration_note(mid):\n",
    "\n",
    "    # Get ticks per beat from the MIDI file\n",
    "    ticks_per_beat = mid.ticks_per_beat\n",
    "\n",
    "    #list of note duration\n",
    "    note_duration_test2 = []\n",
    "\n",
    "    for i, track in enumerate(mid.tracks): \n",
    "        for msg in track:\n",
    "            \n",
    "            if msg.type == 'set_tempo': #take tempo of ticks -> track 0\n",
    "                current_tempo = msg.tempo\n",
    "\n",
    "            elif msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
    "                # Note off: calculate the duration\n",
    "                note_duration_test2.append(tick_to_time_test2(msg.time, current_tempo, ticks_per_beat)) \n",
    "\n",
    "    return note_duration_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATH SONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_all_song(path):\n",
    "\n",
    "    lista_nomi = []\n",
    "    dir_list = os.listdir(path)\n",
    "    \n",
    "\n",
    "    for i in range(len(dir_list)): \n",
    "        song_2 = path + '\\\\' + dir_list[i] \n",
    "        lista_nomi.append(song_2) #save name song\n",
    "        \n",
    "    return lista_nomi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINITION OF K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k (song1, song2):\n",
    "    \n",
    "    min_M = len(song2[\"M\"])\n",
    "    if len(song1[\"M\"]) < len(song2[\"M\"]):\n",
    "        min_M = len(song1[\"M\"])\n",
    "    min_Vm = len(song2[\"Vm\"])\n",
    "    if(len(song1[\"Vm\"]) < len(song2[\"Vm\"])):\n",
    "        min_Vm = len(song1[\"Vm\"])\n",
    "\n",
    "    if(min_M < min_Vm):\n",
    "        k = np.random.randint(low=min_M, high=min_Vm)\n",
    "    else:\n",
    "        k = np.random.randint(low = min_Vm, high=min_M)\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATION OF SUBSET (Sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_subset_of_Vm(Vm, k):\n",
    "    return Vm[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_subset_of_Rm(Rm, k):\n",
    "    return Rm[0:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTE THE WEIGHTED MELODIC/RHYTMIC VECTORIAL DISTANCE BETWEEN SUBSETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s1 : sub_Vm_1\n",
    "#s2 : sub_Vm_2\n",
    "def melodic_vector_distance(s1, s2, list_song):\n",
    "    \n",
    "    distance = 0\n",
    "    \n",
    "    #calculate the eeuclidean distance\n",
    "    for i in range(len(s1)):\n",
    "        \n",
    "        punto1 = s1[i] * (i+1) \n",
    "        punto2 = s2[i] * (i+1)\n",
    "        \n",
    "        absolute_value = abs(punto1 - punto2)\n",
    "        sqrt_abs_value = np.power(absolute_value, 2)\n",
    "        distance += sqrt_abs_value\n",
    "\n",
    "    distance_sub_Vm = np.sqrt(distance)\n",
    "    \n",
    "    return distance_sub_Vm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JACCARD SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Vm and Rm\n",
    "def jaccard_similarity(vector_a, vector_b):\n",
    "    \n",
    "    num = vector_a.intersection(vector_b)\n",
    "    den = vector_a.union(vector_b)\n",
    "    jaccard_result = float(len(num))/float(len(den))\n",
    "\n",
    "    return round(jaccard_result, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBSET SHINGLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_subset_shingles(subset_Vm, k_shingles):\n",
    "\n",
    "    list_shin = []\n",
    "\n",
    "    for i in range(len(subset_Vm)- k_shingles +1):\n",
    "        list_shin.append(subset_Vm[i:i+k_shingles])\n",
    "    \n",
    "    return list_shin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVERAGE JACCARD SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vm\n",
    "def average_jaccard_similarity(list_song, k, k_shingles):\n",
    "    \n",
    "    #1) creation of subset Vm1 and subset Vm2\n",
    "    subset_Vm1 = return_subset_of_Vm(list_song[0][\"Vm\"], k) #Sk(Vm1)\n",
    "    subset_Vm2 = return_subset_of_Vm(list_song[1][\"Vm\"], k) #Sk(Vm2)\n",
    "\n",
    "    #2)divide subset based on len k_shingles\n",
    "    k_shingles_x = return_subset_shingles(subset_Vm1, k_shingles)\n",
    "    k_shingles_y = return_subset_shingles(subset_Vm2, k_shingles)\n",
    "\n",
    "    #3)Compute local jaccard similarity / initialize average jaccard similarity\n",
    "\n",
    "    #total\n",
    "    similarities = []\n",
    "\n",
    "    for x in k_shingles_x:\n",
    "\n",
    "        set_x = set(x)\n",
    "\n",
    "        local_similarities = []\n",
    "        \n",
    "        for y in k_shingles_y:\n",
    "\n",
    "            set_y = set(y)\n",
    "            similarity = jaccard_similarity(set_x, set_y)\n",
    "            local_similarities.append(similarity)\n",
    "\n",
    "        if local_similarities:\n",
    "            \n",
    "            max_similarity = max(local_similarities) \n",
    "            similarities.append(max_similarity)\n",
    "    \n",
    "    #4) compute the average similaities\n",
    "    if similarities:\n",
    "        return sum(similarities) / len(similarities)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rm\n",
    "def average_jaccard_similarity_Rm(list_song, k, k_shingles):\n",
    "    \n",
    "    #1) creation of subset Vm1 and subset Vm2\n",
    "    subset_Rm1 = return_subset_of_Rm(list_song[0][\"Rm\"], k) #Sk(Vm1)\n",
    "    subset_Rm2 = return_subset_of_Rm(list_song[1][\"Rm\"], k) #Sk(Vm2)\n",
    "\n",
    "    #2)divide subset based on len k_shingles\n",
    "    k_shingles_x = return_subset_shingles(subset_Rm1, k_shingles)\n",
    "    k_shingles_y = return_subset_shingles(subset_Rm2, k_shingles)\n",
    "\n",
    "    #3)Compute local jaccard similarity / initialize average jaccard similarity\n",
    "\n",
    "    #total\n",
    "    similarities = []\n",
    "\n",
    "    for x in k_shingles_x:\n",
    "\n",
    "        set_x = set(x)\n",
    "\n",
    "        local_similarities = []\n",
    "        \n",
    "        for y in k_shingles_y:\n",
    "\n",
    "            set_y = set(y)\n",
    "\n",
    "            similarity = jaccard_similarity(set_x, set_y)\n",
    "            local_similarities.append(similarity)\n",
    "\n",
    "        if local_similarities:\n",
    "            \n",
    "            max_similarity = max(local_similarities) \n",
    "            similarities.append(max_similarity)\n",
    "    \n",
    "    #4) compute the average similaities\n",
    "    if similarities:\n",
    "        return sum(similarities) / len(similarities)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART OF FUZZY DEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_lambda(k_shingles_x, k_shingles_y):\n",
    "\n",
    "    #list lambda\n",
    "    list_lambdas = []\n",
    "\n",
    "    for s_y in k_shingles_y:\n",
    "        \n",
    "        #save all the distance before product\n",
    "        distances = []\n",
    "\n",
    "        for s_x in k_shingles_x:  \n",
    "            distance_norm = np.linalg.norm(np.array(s_y) - np.array(s_x)) / max(np.linalg.norm(s_y), np.linalg.norm(s_x)) #d(sx,sy)\n",
    "            distances.append(distance_norm)\n",
    "        \n",
    "        one_minus_distance = [1- d for d in distances] # (1-d(sy,sx))\n",
    "        product_dist = np.prod(one_minus_distance)\n",
    "        lambda_sy_Mx = 1 - product_dist\n",
    "        list_lambdas.append(lambda_sy_Mx)\n",
    "\n",
    "    return list_lambdas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_11384\\1502971217.py:15: RuntimeWarning: overflow encountered in scalar add\n",
      "  distance += sqrt_abs_value\n",
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_11384\\1502971217.py:17: RuntimeWarning: invalid value encountered in sqrt\n",
      "  distance_sub_Vm = np.sqrt(distance)\n",
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_11384\\3397415913.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  distance_norm = np.linalg.norm(np.array(s_y) - np.array(s_x)) / max(np.linalg.norm(s_y), np.linalg.norm(s_x)) #d(sx,sy)\n"
     ]
    }
   ],
   "source": [
    "dict = {\n",
    "    \"name_song\": \"\",\n",
    "    \"M\": [],\n",
    "    \"Vm\": [],\n",
    "    \"Rm\": [],\n",
    "}\n",
    "\n",
    "#list dict for each song\n",
    "list_song_ori = []\n",
    "list_song_plag = []\n",
    "\n",
    "#final ajs\n",
    "list_finals = []\n",
    "\n",
    "#list_real_song\n",
    "list_name_ori = name_all_song(path = \"BMMDet_MPDSet-master\\BMMDet_MPDSet-master\\data\\midi\\dataset_real_ori\")\n",
    "list_name_plag = name_all_song(path = \"BMMDet_MPDSet-master\\BMMDet_MPDSet-master\\data\\midi\\dataset_real_plag\")\n",
    "\n",
    "#scorro le canzoni: -> update folder\n",
    "for i in range(len(list_name_ori)):\n",
    "\n",
    "    #opne file midi\n",
    "    mid_ori = mido.MidiFile(list_name_ori[i])\n",
    "    mid_plag = mido.MidiFile(list_name_plag[i])\n",
    "\n",
    "    #CREO M\n",
    "    M_ori = return_melody(mid_ori)\n",
    "    M_plag = return_melody(mid_plag)\n",
    "\n",
    "    #CREO Vm\n",
    "    Vm_ori = return_delta(M_ori)\n",
    "    Vm_plag = return_delta(M_plag)\n",
    "\n",
    "    #CREO Rm\n",
    "    #list to store note duration test 2\n",
    "    Rm_ori = loop_duration_note(mid_ori)\n",
    "    Rm_plag = loop_duration_note(mid_plag)\n",
    "\n",
    "    dict_ori = {\"name_song\": mid_ori.filename, \"M\":M_ori, \"Vm\":Vm_ori, \"Rm\":Rm_ori}\n",
    "    list_song_ori.append(dict_ori)\n",
    "    dict_plag = {\"name_song\": mid_plag.filename, \"M\":M_plag, \"Vm\":Vm_plag, \"Rm\":Rm_plag}\n",
    "    list_song_plag.append(dict_plag)\n",
    "\n",
    "for i in range(len(list_song_plag)):\n",
    "\n",
    "    #creo kappa \n",
    "    k = find_k(list_song_ori[i], list_song_plag[i])\n",
    "\n",
    "    #find subset of Vm for the 2 songs based on kappa\n",
    "    sub_Vm_1 = return_subset_of_Vm(list_song_ori[i][\"Vm\"], k) #sk (My)\n",
    "    sub_Vm_2 = return_subset_of_Vm(list_song_plag[i][\"Vm\"], k) #sk (Mx)\n",
    "\n",
    "    #calulate the distance for Vm used s1, s2 (subsets)\n",
    "    dist_sub_Vm = melodic_vector_distance(sub_Vm_1, sub_Vm_2, [])\n",
    "\n",
    "    #find the subset of Rm for the 2 songs based on kappa\n",
    "    sub_Rm_1 = return_subset_of_Rm(list_song_ori[i][\"Rm\"], k) #s1\n",
    "    sub_Rm_2 = return_subset_of_Rm(list_song_plag[i][\"Rm\"], k) #s2\n",
    "\n",
    "    ##calulate the distance for Rm used z1, z2 (subsets)\n",
    "    dist_sub_Rm = melodic_vector_distance(sub_Rm_1, sub_Rm_2, [])\n",
    "\n",
    "    #jaccard similarity\n",
    "    js_vm = jaccard_similarity(set(sub_Vm_1), set(sub_Vm_2))\n",
    "    js_rm = jaccard_similarity(set(sub_Rm_1), set(sub_Rm_2))\n",
    "\n",
    "    #k_shingles test\n",
    "    k_shingles = 5\n",
    "\n",
    "    #ajs ckeck list\n",
    "    list_ajs = [list_song_ori[i], list_song_plag[i]]\n",
    "\n",
    "    #average jaccard similarity\n",
    "    ajs_vm = average_jaccard_similarity(list_ajs, k, k_shingles)\n",
    "    ajs_rm = average_jaccard_similarity_Rm(list_ajs, k, k_shingles)\n",
    "\n",
    "    #save\n",
    "    check = {\"plag_song\": list_song_plag[i][\"name_song\"], \"original_song\": list_song_ori[i][\"name_song\"], \"ajs_vm\": ajs_vm, \"ajs_rm\": ajs_rm}\n",
    "    list_finals.append(check)\n",
    "\n",
    "#THRESHOLD\n",
    "list_threshold = []\n",
    "\n",
    "list_threshold_ori = []\n",
    "list_threshold_plag = []\n",
    "\n",
    "for i in list_finals:\n",
    "    if i[\"ajs_vm\"] > 0.2 and i[\"ajs_rm\"] > 0.15 :\n",
    "        list_threshold.append(i)\n",
    "        for y,z in zip(list_song_ori, list_song_plag):\n",
    "            if i[\"original_song\"] == y[\"name_song\"]:\n",
    "                list_threshold_ori.append(y)\n",
    "            if i[\"plag_song\"] == z[\"name_song\"]:\n",
    "                list_threshold_plag.append(z)\n",
    "\n",
    "# FUZZY\n",
    "for i in range(len(list_threshold)): \n",
    "\n",
    "    k = find_k(list_threshold_ori[i], list_threshold_plag[i])\n",
    "\n",
    "    #creation Sk(Vm)\n",
    "    sub_Vm_y = return_subset_of_Vm(list_threshold_ori[i][\"Vm\"], k) #sk (My)\n",
    "    sub_Vm_x = return_subset_of_Vm(list_threshold_plag[i][\"Vm\"], k) #sk (Mx)\n",
    "\n",
    "    #k -> shingles\n",
    "    shi = 5\n",
    "\n",
    "    #2)divide subset based on len k_shingles\n",
    "    k_shingles_y = return_subset_shingles(sub_Vm_y, shi) # sy E sk(My)\n",
    "    k_shingles_x = return_subset_shingles(sub_Vm_x, shi) # sx E sk(Mx)\n",
    "\n",
    "    #compute lambdas\n",
    "    lambda_factors = all_lambda(k_shingles_x, k_shingles_y)\n",
    "    #compute fuzzy\n",
    "    F_My_Mx = sum(lambda_factors) / len(list_threshold_ori[i][\"Vm\"])\n",
    "\n",
    "    list_threshold[i][\"F_My_Mx\"] = F_My_Mx\n",
    "    \n",
    "#FINAL\n",
    "\n",
    "alpha = 0.75\n",
    "\n",
    "final = []\n",
    "\n",
    "for i in list_threshold:\n",
    "    if i[\"F_My_Mx\"] >= alpha:\n",
    "        final.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'plag_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_plag\\\\case10_Schenkt uns Dummheit, kein Niveau-FreiWild.mid',\n",
       "  'original_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_ori\\\\case10_Anftrag Deutsches Reich-Stahlgewitter.mid',\n",
       "  'ajs_vm': 0.8059197368421053,\n",
       "  'ajs_rm': 0.9561447368421053,\n",
       "  'F_My_Mx': 0.95},\n",
       " {'plag_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_plag\\\\case17_perhaps.mid',\n",
       "  'original_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_ori\\\\case17_ma este meg.mid',\n",
       "  'ajs_vm': 0.8352557692307696,\n",
       "  'ajs_rm': 0.678251923076923,\n",
       "  'F_My_Mx': 0.8},\n",
       " {'plag_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_plag\\\\case19_Till you.mid',\n",
       "  'original_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_ori\\\\case19_phantom Song.mid',\n",
       "  'ajs_vm': 0.5745243243243243,\n",
       "  'ajs_rm': 0.3790378378378379,\n",
       "  'F_My_Mx': 0.8222222222222222},\n",
       " {'plag_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_plag\\\\case1_song_b.mid',\n",
       "  'original_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_ori\\\\case1_song_a.mid',\n",
       "  'ajs_vm': 0.7113755102040814,\n",
       "  'ajs_rm': 0.8707591836734689,\n",
       "  'F_My_Mx': 0.9245283018867925},\n",
       " {'plag_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_plag\\\\case21_Filion Family Welcome.mid',\n",
       "  'original_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_ori\\\\case21_Here We Are On the Road Again.mid',\n",
       "  'ajs_vm': 0.5068894736842104,\n",
       "  'ajs_rm': 0.39787894736842105,\n",
       "  'F_My_Mx': 0.9047619047619248},\n",
       " {'plag_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_plag\\\\case22_Chariots of Fire.mid',\n",
       "  'original_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_ori\\\\case22_City of Violets.mid',\n",
       "  'ajs_vm': 0.2996933333333333,\n",
       "  'ajs_rm': 0.3142866666666667,\n",
       "  'F_My_Mx': 0.7894736141215655},\n",
       " {'plag_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_plag\\\\case25_Advert for Rapid Coach Service.mid',\n",
       "  'original_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_ori\\\\case25_There is nothin_ like a dame.mid',\n",
       "  'ajs_vm': 0.30007959183673466,\n",
       "  'ajs_rm': 0.4090346938775509,\n",
       "  'F_My_Mx': 0.765625},\n",
       " {'plag_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_plag\\\\case28_my sweet lord.mid',\n",
       "  'original_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_ori\\\\case28_he so fine.mid',\n",
       "  'ajs_vm': 0.8138243902439024,\n",
       "  'ajs_rm': 0.6283341463414636,\n",
       "  'F_My_Mx': 0.82},\n",
       " {'plag_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_plag\\\\case4_我爱你中国.mid',\n",
       "  'original_song': 'BMMDet_MPDSet-master\\\\BMMDet_MPDSet-master\\\\data\\\\midi\\\\dataset_real_ori\\\\case4_十月里响起一声春雷.mid',\n",
       "  'ajs_vm': 0.8042419075144515,\n",
       "  'ajs_rm': 0.8036774566473988,\n",
       "  'F_My_Mx': 0.9276139410187667}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
